{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Open Llama 7B (v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acfad9658bf4e8f92b238e9aa93ab84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Caminho do modelo\n",
    "model_path = '/var/ontologia/Servicos/ACS_LLMS/server/models/open_llama_7b'\n",
    "\n",
    "# Configuração do dispositivo (GPU se disponível, caso contrário CPU)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cuda:2\"\n",
    "\n",
    "# Carregar o tokenizador e o modelo\n",
    "model = LlamaForCausalLM.from_pretrained(model_path).to(device)  \n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Os investimentos em renda fixa são considerados uma das opções mais seguras do mercado financeiro e são especialmente atraentes para investidores com perfil conservador. Esses investimentos são compostos principalmente por títulos de dívida, seja pública ou privada. No Brasil, muitos bancos, incluindo o Banco do Brasil, oferecem uma variedade de opções de investimento em renda fixa. Esses investimentos têm como característica principal o retorno previsível, e o rendimento, na maioria das vezes, é acordado no momento da aplicação.\n",
      "- **CDB (Certificado de Depósito Bancário)**: O CDB pode ser encontrado em 3 modalidades: prefixada, pós-fixada e progressiva. Enquanto o CDB prefixado tem um rendimento acordado no ato da aplicação, o pós-fixado e o progressivo são atrelados ao CDI, com o último tendo sua taxa definida com base no tempo de permanência da aplicação. Apesar do prazo de vencimento, o CDB pós-fixado e o progressivo podem ser resgatados a qualquer momento. É adequado para investidores que buscam mais rentabilidade do que a poupança e estão dispostos a abrir mão da liquidez diária. \n",
      "- **LCI e LCA**: Ambos são títulos emitidos por bancos para financiar respectivamente o setor imobiliário e agrícola. São ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia, como imobiliário ou agrícola. \n",
      "- **Títulos do Tesouro Direto**: Existem diversas modalidades, como o Tesouro Selic, ideal para reserva de emergência; Tesouro Prefixado, para quem acredita que a taxa de juros e a inflação vão cair, e Tesouro IPCA+, indicado para quem deseja proteger seu dinheiro contra a inflação. Recomendados para quem busca diversificar sua carteira de investimentos com opções seguras. São títulos públicos emitidos pelo governo federal e são considerados os investimentos mais seguros do país devido à garantia do governo federal. \n",
      "A maioria desses investimentos tem a proteção do FGC (Fundo Garantidor de Créditos), o que os torna ainda mais seguros para os investidores. Além disso, o Banco do Brasil, uma das principais instituições financeiras do país, oferece todas essas opções de investimento com diferentes vantagens e condições, atendendo a diversos perfis de investidores, desde os mais conservadores até os mais arrojados.\n",
      "\n",
      "\n",
      "Q: Com base no texto, explique qual é o investimento mais adequado para alguém que busca proteção contra a inflação?\n",
      "A: O investimento mais adequado para alguém que busca proteção contra a inflação é o Tesouro IPCA+, que é um título do Tesouro Direto, que é um título público emitido pelo governo federal e que é considerado o investimento mais seguro do país devido à garantia do governo federal.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contexto e questão\n",
    "\n",
    "context = r\"\"\"\n",
    "Os investimentos em renda fixa são considerados uma das opções mais seguras do mercado financeiro e são especialmente atraentes para investidores com perfil conservador. Esses investimentos são compostos principalmente por títulos de dívida, seja pública ou privada. No Brasil, muitos bancos, incluindo o Banco do Brasil, oferecem uma variedade de opções de investimento em renda fixa. Esses investimentos têm como característica principal o retorno previsível, e o rendimento, na maioria das vezes, é acordado no momento da aplicação.\n",
    "- **CDB (Certificado de Depósito Bancário)**: O CDB pode ser encontrado em 3 modalidades: prefixada, pós-fixada e progressiva. Enquanto o CDB prefixado tem um rendimento acordado no ato da aplicação, o pós-fixado e o progressivo são atrelados ao CDI, com o último tendo sua taxa definida com base no tempo de permanência da aplicação. Apesar do prazo de vencimento, o CDB pós-fixado e o progressivo podem ser resgatados a qualquer momento. É adequado para investidores que buscam mais rentabilidade do que a poupança e estão dispostos a abrir mão da liquidez diária. \n",
    "- **LCI e LCA**: Ambos são títulos emitidos por bancos para financiar respectivamente o setor imobiliário e agrícola. São ideais para investidores que buscam isenção de Imposto de Renda e desejam investir em setores específicos da economia, como imobiliário ou agrícola. \n",
    "- **Títulos do Tesouro Direto**: Existem diversas modalidades, como o Tesouro Selic, ideal para reserva de emergência; Tesouro Prefixado, para quem acredita que a taxa de juros e a inflação vão cair, e Tesouro IPCA+, indicado para quem deseja proteger seu dinheiro contra a inflação. Recomendados para quem busca diversificar sua carteira de investimentos com opções seguras. São títulos públicos emitidos pelo governo federal e são considerados os investimentos mais seguros do país devido à garantia do governo federal. \n",
    "A maioria desses investimentos tem a proteção do FGC (Fundo Garantidor de Créditos), o que os torna ainda mais seguros para os investidores. Além disso, o Banco do Brasil, uma das principais instituições financeiras do país, oferece todas essas opções de investimento com diferentes vantagens e condições, atendendo a diversos perfis de investidores, desde os mais conservadores até os mais arrojados.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Com base no texto, explique qual é o investimento mais adequado para alguém que busca proteção contra a inflação?\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generate_ids = model.generate(input_ids=input_ids, max_new_tokens=89)  # Ajustar o max_new_tokens conforme necessário\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão.\n",
      "A:\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.0\n"
     ]
    }
   ],
   "source": [
    "#################  ICL com self-reflection  #################\n",
    "\n",
    "context = r\"\"\" \"\"\"\n",
    "question = \"Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão.\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=30,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.decode(generation_output[0])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################  COMPREENSÃO E GERAÇÃO DE TEXTO  ####################################################################\n",
    "####################################################################  AVALIAÇÃO DA SEMÂNTICA PT-BR  ####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem por mais de 2.300 quilômetros. Está localizado no Mar de Coral, na costa da Austrália. O recife abriga uma grande variedade de vida marinha, incluindo mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies.\n",
      "\n",
      "\n",
      "Q: O que é a Grande Barreira de Corais e onde ela está localizada?\n",
      "A: A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem por mais de 2.300 quilômetros. Está localizado no Mar de Coral, na costa da Austrália.\n"
     ]
    }
   ],
   "source": [
    "################# Question Answering de Simples Compreensão de Texto #################\n",
    "\n",
    "context = r\"\"\"\n",
    "A Grande Barreira de Corais é o maior sistema de recifes de corais do mundo, composto por mais de 2.900 recifes individuais e 900 ilhas que se estendem por mais de 2.300 quilômetros. Está localizado no Mar de Coral, na costa da Austrália. O recife abriga uma grande variedade de vida marinha, incluindo mais de 1.500 espécies de peixes, 600 tipos de corais e inúmeras outras espécies.\n",
    "\"\"\"\n",
    "question = \"O que é a Grande Barreira de Corais e onde ela está localizada?\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) \n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=90,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.decode(generation_output[0])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "Sabemos onde realmente está a pipa em nosso coração? Não conseguiremos isso de novo se perdermos isso na vida, talvez nos arrependamos e nos redimamos, mas tudo isso parece ser tarde demais. Sempre que a pipa é lançada no céu, não deveríamos nos perguntar se realmente valorizamos o que temos?\n",
      "Cada um de nós fez algo na juventude que nos envergonhará no futuro. Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela. Mas o tempo não vai mudar, os seus melhores esforços para compensar isso, como não é uma espécie de auto-ajuda? A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
      "Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar. Para você, mil vezes, todo o corpo ainda estará justo, talvez isso seja a vida, a vida não é apenas fazer coisas que valem a pena!\n",
      "\n",
      "\n",
      "Q: Resuma o parágrafo apresentado\n",
      "A: A vida é uma coisa que não se pode fazer, é uma coisa que se pode fazer.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Question Answering de Simples Compreensão de Texto #################\n",
    "\n",
    "context = r\"\"\"\n",
    "Sabemos onde realmente está a pipa em nosso coração? Não conseguiremos isso de novo se perdermos isso na vida, talvez nos arrependamos e nos redimamos, mas tudo isso parece ser tarde demais. Sempre que a pipa é lançada no céu, não deveríamos nos perguntar se realmente valorizamos o que temos?\n",
    "Cada um de nós fez algo na juventude que nos envergonhará no futuro. Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela. Mas o tempo não vai mudar, os seus melhores esforços para compensar isso, como não é uma espécie de auto-ajuda? A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
    "Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar. Para você, mil vezes, todo o corpo ainda estará justo, talvez isso seja a vida, a vida não é apenas fazer coisas que valem a pena!\n",
    "\"\"\"\n",
    "question = \"Resuma o parágrafo apresentado\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.decode(generation_output[0])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\n",
      "A: A minha resposta é 1.00.\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à minha questão. Além da autoavaliação de nota, responde a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\n",
      "A: A minha resposta é 1.00.\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à minha questão. Além da autoavaliação de nota, responde a\n"
     ]
    }
   ],
   "source": [
    "#################  ICL com self-reflection  #################\n",
    "\n",
    "context = r\"\"\" \"\"\"\n",
    "question = \"Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. \\\n",
    "Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=200,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.decode(generation_output[0])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<Exemplos>>\n",
      "Exemplo 1:\n",
      "Dados divulgados pelo Departamento Nacional de Seguro de Saúde mostraram que de janeiro a março de 2023, a receita total do fundo de seguro médico básico (incluindo seguro de maternidade) foi de 910,48 bilhões de yuans, um aumento de 9,5% em relação ao ano anterior.\n",
      "---- Categoria: Medicina\n",
      "\n",
      "Exemplo 2:\n",
      "A Berkshire Hathaway reduziu sua participação nas ações da BYD de 10,05% para 9,87%. A HKEx Disclosure Ease exige divulgação quando um acionista majoritário aumenta ou diminui sua participação acionária somente se ultrapassar uma determinada porcentagem.\n",
      "---- Categoria: Finanças\n",
      "\n",
      "\n",
      "Q: \n",
      "Exemplo 3:\n",
      "Os produtos de edge computing têm sido aplicados em setores como educação on-line, vídeo, jogos e carros conectados.\n",
      "---- Categoria: ?\n",
      "Substitua o termo '?'\n",
      "\n",
      "A: Você pode usar o seguinte exemplo:\n",
      "\n",
      "Exemplo 3:\n",
      "Os produtos de edge computing têm sido aplicados em setores como educação on-line, vídeo, jogos e carros conectados.\n",
      "---- Categoria: ?\n",
      "Substitua o termo '?'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Dedução Lógica de Intenções #################\n",
    "\n",
    "context = r\"\"\"\n",
    "<<Exemplos>>\n",
    "Exemplo 1:\n",
    "Dados divulgados pelo Departamento Nacional de Seguro de Saúde mostraram que de janeiro a março de 2023, a receita total do fundo de seguro médico básico (incluindo seguro de maternidade) foi de 910,48 bilhões de yuans, um aumento de 9,5% em relação ao ano anterior.\n",
    "---- Categoria: Medicina\n",
    "\n",
    "Exemplo 2:\n",
    "A Berkshire Hathaway reduziu sua participação nas ações da BYD de 10,05% para 9,87%. A HKEx Disclosure Ease exige divulgação quando um acionista majoritário aumenta ou diminui sua participação acionária somente se ultrapassar uma determinada porcentagem.\n",
    "---- Categoria: Finanças\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Exemplo 3:\n",
    "Os produtos de edge computing têm sido aplicados em setores como educação on-line, vídeo, jogos e carros conectados.\n",
    "---- Categoria: ?\n",
    "Substitua o termo '?'\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=100,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não conseguiu concluir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. Observação: o prompt original teve que ser muito alterado para deixar explícita a intenção da questão, do contrário, nos testes empíricos o modelo (você) teve muita dificuldade em compreender a lógica. Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação a inferência lógica?\n",
      "A: A resposta é:\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*A dificuldade de compreender a lógica da questão.\n",
      "\n",
      "*A dificuldade de compreender o que é a lógica da questão.\n",
      "\n",
      "*A dificuldade de compreender o que é a lógica da questão.\n",
      "\n",
      "*A dificuldade de compreender o que é a lógica da quest\n"
     ]
    }
   ],
   "source": [
    "#################  ICL com self-reflection  #################\n",
    "\n",
    "context = r\"\"\" \"\"\"\n",
    "question = \"Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. \\\n",
    "    Observação: o prompt original teve que ser muito alterado para deixar explícita a intenção da questão, do contrário, nos testes empíricos o modelo (você) teve muita dificuldade em compreender a lógica. \\\n",
    "        Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação a inferência lógica?\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=100,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.decode(generation_output[0])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "A criação de questões de múltipla escolha para exames de história requer não apenas um entendimento profundo do período histórico, mas também a habilidade de formular perguntas que avaliem adequadamente o conhecimento dos alunos. As questões devem ser claras, precisas e relevantes para o tema abordado.\n",
      "\n",
      "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renacimento, com mais de uma alternativa correta, obrigatoriamente.\n",
      "Demonstração: \n",
      " Questão:\n",
      " Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      " (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
      " Alternativas corretas: A resposta correta é: A e C.\n",
      " Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinci, Michelangelo e Dante. Londres também cresceu rapidamente durante a Renascença para se tornar um centro cultural e comercial da Europa, atraindo muitas celebridades culturais e comerciantes. Portanto, as opções A e C são as respostas corretas.\n",
      "\n",
      "\n",
      "Q: \n",
      "Suponha que você seja um professor de história com mais de 30 anos de experiência docente.\n",
      "Instruções: Crie uma Questão de múltipla escolha para uma prova de história.\n",
      "Relevância: A questão deveria estar relacionada ao Renascimento.\n",
      "Restrição: Você deve criar uma NOVA Questão (diferente da Demonstração e também com 2 alternativas corretas), suas Alternativas corretas e Explicação.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e C.\n",
      "\n",
      "A: Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
      "\n",
      "A: A resposta correta é A e\n"
     ]
    }
   ],
   "source": [
    "################# \"World Knowledge\" e Compreensão de Intenções (com Demonstração) #################\n",
    "\n",
    "context = \"\"\"\n",
    "A criação de questões de múltipla escolha para exames de história requer não apenas um entendimento profundo do período histórico, mas também a habilidade de formular perguntas que avaliem adequadamente o conhecimento dos alunos. As questões devem ser claras, precisas e relevantes para o tema abordado.\n",
    "\n",
    "Pergunta: Crie uma pergunta de múltipla escolha sobre o Renacimento, com mais de uma alternativa correta, obrigatoriamente.\n",
    "Demonstração: \n",
    "    Questão:\n",
    "      Durante o Renascimento, qual ou quais das seguintes cidades eram um centro cultural?\n",
    "        (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
    "      Alternativas corretas: A resposta correta é: A e C.\n",
    "      Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinci, Michelangelo e Dante. Londres também cresceu rapidamente durante a Renascença para se tornar um centro cultural e comercial da Europa, atraindo muitas celebridades culturais e comerciantes. Portanto, as opções A e C são as respostas corretas.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Suponha que você seja um professor de história com mais de 30 anos de experiência docente.\n",
    "Instruções: Crie uma Questão de múltipla escolha para uma prova de história.\n",
    "Relevância: A questão deveria estar relacionada ao Renascimento.\n",
    "Restrição: Você deve criar uma NOVA Questão (diferente da Demonstração e também com 2 alternativas corretas), suas Alternativas corretas e Explicação.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=500,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.decode(generation_output[0])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "<<Demonstração>>\n",
      "Pergunta: Durante o Renascimento, qual das seguintes cidades era um centro cultural?\n",
      " (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
      "A resposta correta é: A e C.\n",
      " Resposta Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinci, Michelangelo e Dante. Londres também cresceu rapidamente durante a Renascença para se tornar um centro cultural e comercial da Europa, atraindo muitas celebridades culturais e comerciantes. Portanto, as opções A e C são as respostas corretas.\n",
      "\n",
      "\n",
      "Q: Suponha que você seja um professor de história com mais de 30 anos de experiência docente.Instruções: Escreva uma pergunta de múltipla escolha para uma prova de história. A pergunta deve ser diferente da pergunta da <<Demonstração>>.Relevância: A questão deveria estar relacionada ao Renascimento.Restrição: Deve haver mais de duas respostas corretas entre as quatro opções. Oriente o aluno a assinalá-las.\n",
      "A: Durante o Renascimento, qual das seguintes cidades era um centro cultural?\n",
      " (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
      "A resposta correta é: A e C.\n",
      " Resposta Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinci, Michelangelo e Dante. Londres também cresceu rapidamente durante a Renascença para se tornar um centro cultural e comercial da Europa, atraindo muitas celebridades culturais e comerciantes. Portanto, as opções A e C são as respostas corretas.\n",
      "\n",
      "\n",
      "Q: Suponha que você seja um professor de história com mais de 30 anos de experiência docente.Instruções: Escreva uma pergunta de múltipla escolha para uma prova de história. A pergunta deve ser diferente da pergunta da <<Demonstração>>.Relevância: A questão deveria estar relacionada ao Renascimento.Restrição: Deve haver mais de duas respostas corretas entre as quatro opções. Oriente o aluno a assinalá-las.\n",
      "A: Durante o Renascimento, qual das seguintes cidades era um centro cultural?\n",
      " (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
      "A resposta correta é: A e C.\n",
      " Resposta Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinc\n"
     ]
    }
   ],
   "source": [
    "################# \"World Knowledge\" e Compreensão de Intenções (com Demonstração) #################\n",
    "\n",
    "context = r\"\"\"\n",
    "<<Demonstração>>\n",
    "Pergunta: Durante o Renascimento, qual das seguintes cidades era um centro cultural?\n",
    "  (A) Londres (B) Paris (C) Florença (D) Amsterdã\n",
    "A resposta correta é: A e C.\n",
    "  Resposta Explicação: Durante o Renascimento, Florença foi um dos centros culturais mais importantes da Europa, onde muitos artistas, estudiosos e pensadores importantes trabalharam e viveram, incluindo Leonardo da Vinci, Michelangelo e Dante. Londres também cresceu rapidamente durante a Renascença para se tornar um centro cultural e comercial da Europa, atraindo muitas celebridades culturais e comerciantes. Portanto, as opções A e C são as respostas corretas.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Suponha que você seja um professor de história com mais de 30 anos de experiência docente.\\\n",
    "Instruções: Escreva uma pergunta de múltipla escolha para uma prova de história. A pergunta deve ser diferente da pergunta da <<Demonstração>>.\\\n",
    "Relevância: A questão deveria estar relacionada ao Renascimento.\\\n",
    "Restrição: Deve haver mais de duas respostas corretas entre as quatro opções. Oriente o aluno a assinalá-las.\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=500,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.decode(generation_output[0])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas overtraining. Apenas copiou o exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\n",
      "A: A minha resposta é 1.00.\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à minha questão. Além da autoavaliação de nota, responde a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\n",
      "A: A minha resposta é 1.00.\n",
      "\n",
      "Q: Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à minha questão. Além da autoavaliação de nota, responde a\n"
     ]
    }
   ],
   "source": [
    "#################  ICL com self-reflection  #################\n",
    "\n",
    "context = r\"\"\" \"\"\"\n",
    "question = \"Em seguida, faça uma autoavaliação e atribua-se uma nota de 0.00 a 1.00, avaliando a qualidade da sua resposta à questão. \\\n",
    "Além da autoavaliação de nota, responda a minha questão: quais dificuldades ou limitações você reconhece ter em relação à compreensão de texto?\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=200,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.decode(generation_output[0])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frases para Agrupar:\n",
      "1. \"A produção industrial está em alta este mês.\"\n",
      "2. \"Agricultores relatam uma colheita abundante nesta temporada.\"\n",
      "3. \"O crescimento econômico acelerou no último trimestre.\"\n",
      "\n",
      "Agrupamento:\n",
      " Frases 1 e 3: Ambas tratam de crescimento econômico.\n",
      " Frase 2: Trata de agricultura, não se encaixa diretamente com as outras duas sobre economia.\n",
      "\n",
      "Frases para Agrupar:\n",
      "1. \"Pesquisadores descobrem um novo tipo de antibiótico no solo da floresta tropical.\"\n",
      "2. \"A conferência de tecnologia revela inovações em inteligência artificial.\"\n",
      "3. \"Novo método de reciclagem aumenta a eficiência na conversão de resíduos plásticos.\"\n",
      "\n",
      "Agrupamento:\n",
      " Frase 1: Relacionada a descobertas científicas.\n",
      " Frases 2 e 3: Relacionadas a inovações tecnológicas.\n",
      "\n",
      "\n",
      "Q: \n",
      "Frases para Agrupar:\n",
      "\n",
      "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
      "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
      "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
      "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\"\n",
      "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
      "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
      "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
      "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
      "\n",
      "Pergunta:\n",
      "Esta é uma tarefa de agrupamento de frases similares. Agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade semântica entre elas.\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Categorização e Clustering / Agrupamento #################\n",
    "\n",
    "context = \"\"\"\n",
    "Frases para Agrupar:\n",
    "1. \"A produção industrial está em alta este mês.\"\n",
    "2. \"Agricultores relatam uma colheita abundante nesta temporada.\"\n",
    "3. \"O crescimento econômico acelerou no último trimestre.\"\n",
    "\n",
    "Agrupamento:\n",
    "    Frases 1 e 3: Ambas tratam de crescimento econômico.\n",
    "    Frase 2: Trata de agricultura, não se encaixa diretamente com as outras duas sobre economia.\n",
    "\n",
    "Frases para Agrupar:\n",
    "1. \"Pesquisadores descobrem um novo tipo de antibiótico no solo da floresta tropical.\"\n",
    "2. \"A conferência de tecnologia revela inovações em inteligência artificial.\"\n",
    "3. \"Novo método de reciclagem aumenta a eficiência na conversão de resíduos plásticos.\"\n",
    "\n",
    "Agrupamento:\n",
    "    Frase 1: Relacionada a descobertas científicas.\n",
    "    Frases 2 e 3: Relacionadas a inovações tecnológicas.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Frases para Agrupar:\n",
    "\n",
    "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
    "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
    "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
    "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\"\n",
    "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
    "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
    "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
    "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
    "\n",
    "Pergunta:\n",
    "Esta é uma tarefa de agrupamento de frases similares. Agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade semântica entre elas.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
      "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
      "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
      "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\" \n",
      "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
      "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
      "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
      "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
      "\n",
      "\n",
      "Q: \n",
      "Esta é uma tarefa de agrupamento de frases similares.\n",
      "Agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade semântica entre elas.\n",
      "\n",
      "\n",
      "A: Você pode usar o seguinte algoritmo:\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*Criar um array com todas as frases.\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"carros elétricos\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"café\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as frases que contenham o termo \"câmera aprimorada\".\n",
      "\n",
      "*Criar um array com todas as fr\n"
     ]
    }
   ],
   "source": [
    "################# Categorização e Clustering / Agrupamento #################\n",
    "\n",
    "context = r\"\"\"\n",
    "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
    "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
    "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
    "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\" \n",
    "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
    "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
    "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
    "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Esta é uma tarefa de agrupamento de frases similares.\n",
    "Agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade semântica entre elas.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
      "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
      "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
      "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\" \n",
      "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
      "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
      "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
      "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
      "\n",
      "\n",
      "Q: \n",
      "Esta é uma tarefa de agrupamento de frases similares.\n",
      "Crie categorias semânticas e agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade entre elas.\n",
      "\n",
      "A: Você pode usar o seguinte código:\n",
      "\n",
      "\n",
      "var frases = [\n",
      " \"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\",\n",
      " \"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\",\n",
      " \"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\",\n",
      " \"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\",\n",
      " \"Amazon anuncia planos para construir um novo centro de distribuição no Texas\",\n",
      " \"Cientistas descobrem novas espécies de aves na floresta amazônica\",\n",
      " \"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
      "];\n",
      "\n",
      "var frases_categorias = [];\n",
      "\n",
      "frases.forEach(function(frase) {\n",
      " var categoria = frase.match(/(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?)\\s(.*?\n"
     ]
    }
   ],
   "source": [
    "################# Categorização e Clustering / Agrupamento #################\n",
    "\n",
    "context = r\"\"\"\n",
    "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
    "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
    "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
    "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\" \n",
    "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
    "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
    "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
    "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Esta é uma tarefa de agrupamento de frases similares.\n",
    "Crie categorias semânticas e agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade entre elas.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "################# Clustering ou Agrupamento #################\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
      "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
      "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
      "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\" \n",
      "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
      "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
      "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
      "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
      "\n",
      "\n",
      "Q: \n",
      "Esta é uma tarefa de agrupamento de frases similares.\n",
      "Agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade semântica entre elas.\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Categorização e Clustering / Agrupamento #################\n",
    "\n",
    "context = r\"\"\"\n",
    "\"As vendas de carros elétricos da Tesla continuam a subir apesar da pandemia\"\n",
    "\"Novo estudo sugere que o consumo de café pode diminuir o risco de doenças cardíacas\"\n",
    "\"O modelo mais recente do iPhone apresenta uma tela maior e câmera aprimorada\"\n",
    "\"Casos de COVID-19 aumentam na Índia, sobrecarregando o sistema de saúde\" \n",
    "\"Amazon anuncia planos para construir um novo centro de distribuição no Texas\"\n",
    "\"Cientistas descobrem novas espécies de aves na floresta amazônica\"\n",
    "\"Conferência global sobre mudanças climáticas será realizada em Paris no próximo mês\"\n",
    "\"Starbucks apresenta opções de leite vegetal em todas as lojas dos EUA\"\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Esta é uma tarefa de agrupamento de frases similares.\n",
    "Agrupe as 8 frases apresentadas em grupos de 2 ou 3 frases, por critério de similaridade semântica entre elas.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sabemos onde realmente está a pipa em nosso coração? Não conseguiremos isso de novo se perdermos isso na vida, talvez nos arrependamos e nos redimamos, mas tudo isso parece ser tarde demais. Sempre que a pipa é lançada no céu, não deveríamos nos perguntar se realmente valorizamos o que temos?\n",
      "Cada um de nós fez algo na juventude que nos envergonhará no futuro. Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela. Mas o tempo não vai mudar, os seus melhores esforços para compensar isso, como não é uma espécie de auto-ajuda? A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
      "Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar. Para você, mil vezes, todo o corpo ainda estará justo, talvez isso seja a vida, a vida não é apenas fazer coisas que valem a pena!\n",
      "\n",
      "\n",
      "Q: \n",
      "Resuma o parágrafo apresentado\n",
      "\n",
      "A:\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*A pipa é uma coisa que você fez na juventude que nos envergonhará no futuro.\n",
      "\n",
      "*Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela.\n",
      "\n",
      "*A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
      "\n",
      "*Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*Resumo o parágrafo apresentado\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*A pipa é uma coisa que você fez na juventude que nos envergonhará no futuro.\n",
      "\n",
      "*Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela.\n",
      "\n",
      "*A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
      "\n",
      "*Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*Resumo o parágrafo apresentado\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*A pipa é uma coisa que você fez na juventude que nos envergonhará no futuro.\n",
      "\n",
      "*Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela.\n",
      "\n",
      "*A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
      "\n",
      "*Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*Resumo o parágrafo apresentado\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*A pipa é uma coisa que você fez na juventude que nos envergonhará no futuro.\n",
      "\n",
      "*Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela.\n",
      "\n",
      "*A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
      "\n",
      "*Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*Resum\n"
     ]
    }
   ],
   "source": [
    "################# Sumarização de Texto #################\n",
    "################# \"World Knowledge\" e Compreensão #################\n",
    "\n",
    "context = r\"\"\"\n",
    "Sabemos onde realmente está a pipa em nosso coração? Não conseguiremos isso de novo se perdermos isso na vida, talvez nos arrependamos e nos redimamos, mas tudo isso parece ser tarde demais. Sempre que a pipa é lançada no céu, não deveríamos nos perguntar se realmente valorizamos o que temos?\n",
    "Cada um de nós fez algo na juventude que nos envergonhará no futuro. Essas coisas podem ser como uma sombra que o acompanha pelo resto da vida, de modo que você só consegue olhar para ela. Mas o tempo não vai mudar, os seus melhores esforços para compensar isso, como não é uma espécie de auto-ajuda? A beleza e a amizade da infância, por causa de uma negligência covarde e arruinada, se você tiver outra chance, você está disposto a se esforçar para recuperar aquele antigo eu?\n",
    "Mas as pessoas são assim, vivem sempre dentro de um determinado limite de tempo, onde o mundo pode estar alguns anos depois nem elas conseguem entender, mas é isso que não conseguimos superar. Para você, mil vezes, todo o corpo ainda estará justo, talvez isso seja a vida, a vida não é apenas fazer coisas que valem a pena!\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Resuma o parágrafo apresentado\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Escrever é esquecer. A literatura é a maneira mais agradável de ignorar a vida. \n",
      "A música embala, as artes visuais animam, as artes vivas (como a dança e a arte de representar) entretêm. \n",
      "A primeira, porém, afasta-se da vida por fazer dela um sono; as segundas, contudo, não se afastam da vida - umas porque usam de fórmulas visíveis e portanto vitais, outras porque vivem da mesma vida humana.\n",
      "Não é o caso da literatura. Essa simula a vida. Um romance é uma história do que nunca foi e um drama é um romance dado sem narrativa. \n",
      "Um poema é a expressão de ideias ou de sentimentos em linguagem que ninguém emprega, pois que ninguém fala em verso.\"\n",
      "Fernando Pessoa\n",
      "\n",
      "\n",
      "Q: \n",
      "Resuma o texto apresentado\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Sumarização de Texto #################\n",
    "################# \"World Knowledge\" e Compreensão #################\n",
    "\n",
    "context = r\"\"\"\n",
    "\"Escrever é esquecer. A literatura é a maneira mais agradável de ignorar a vida. \n",
    "A música embala, as artes visuais animam, as artes vivas (como a dança e a arte de representar) entretêm. \n",
    "A primeira, porém, afasta-se da vida por fazer dela um sono; as segundas, contudo, não se afastam da vida - umas porque usam de fórmulas visíveis e portanto vitais, outras porque vivem da mesma vida humana.\n",
    "Não é o caso da literatura. Essa simula a vida. Um romance é uma história do que nunca foi e um drama é um romance dado sem narrativa. \n",
    "Um poema é a expressão de ideias ou de sentimentos em linguagem que ninguém emprega, pois que ninguém fala em verso.\"\n",
    "Fernando Pessoa\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Resuma o texto apresentado\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Writing is forgetting. Literature is the most pleasant way to ignore life. Music excites, the visual arts enliven, the living arts (such as dance and the art of acting) entertain. The first, however, moves away from life by making it a sleep; the second, however, do not move away from life - some because they use visible and therefore vital formulas, others because they live from the same human life.\n",
      "It is not the case of the literacy. This simulates life. A novel is a story of what never was and a drama is a novel given without narrative. A poem is the expression of ideas or feelings in language that no one uses, since no one speaks in verse.\"\n",
      "Fernando Pessoa\n",
      "\n",
      "\n",
      "Q: \n",
      "Summarize the presented extract\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*The author is Fernando Pessoa.\n",
      "\n",
      "*The extract is from his essay \"The Art of Writing\".\n",
      "\n",
      "*The extract is about the difference between the arts.\n",
      "\n",
      "*The author says that writing is forgetting.\n",
      "\n",
      "*Literature is the most pleasant way to ignore life.\n",
      "\n",
      "*Music excites, the visual arts enliven, the living arts (such as dance and the art of acting) entertain.\n",
      "\n",
      "*The first, however, moves away from life by making it a sleep; the second, however, do not move away from life - some because they use visible and therefore vital formulas, others because they live from the same human life.\n",
      "\n",
      "*It is not the case of the literacy. This simulates life. A novel is a story of what never was and a drama is a novel given without narrative. A poem is the expression of ideas or feelings in language that no one uses, since no one speaks in verse.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "What is the author's attitude towards the arts?\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*The author is Fernando Pessoa.\n",
      "\n",
      "*The extract is from his essay \"The Art of Writing\".\n",
      "\n",
      "*The extract is about the difference between the arts.\n",
      "\n",
      "*The author says that writing is forgetting.\n",
      "\n",
      "*Literature is the most pleasant way to ignore life.\n",
      "\n",
      "*Music excites, the visual arts enliven, the living arts (such as dance and the art of acting) entertain.\n",
      "\n",
      "*The first, however, moves away from life by making it a sleep; the second, however, do not move away from life - some because they use visible and therefore vital formulas, others because they live from the same human life.\n",
      "\n",
      "*It is not the case of the literacy. This simulates life. A novel is a story of what never was and a drama is a novel given without narrative. A poem is the expression of ideas or feelings in language that no one uses, since no one speaks in verse.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "What is the author's attitude towards the arts?\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*The author is Fernando Pessoa.\n",
      "\n",
      "*The extract is from his essay \"The Art of Writing\".\n",
      "\n",
      "*The extract is about the difference between the arts.\n",
      "\n",
      "*The author says that writing is forgetting.\n",
      "\n",
      "*Literature is the most pleasant way to ignore life.\n",
      "\n",
      "*Music excites, the visual arts enliven, the living arts (such as dance and the art of acting) entertain.\n",
      "\n",
      "*The first, however, moves away from life by making it a sleep; the second, however, do not move away from life - some because they use visible and therefore vital formulas, others because they live from the same human life.\n",
      "\n",
      "*It is not the case of the literacy. This simulates life. A novel is a story of what never was and a drama is a novel given without narrative. A poem is the expression of ideas or feelings in language that no one uses, since no one speaks in verse.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "What is the author's attitude towards the arts?\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*The author is Fernando Pessoa.\n",
      "\n",
      "*The extract is from his essay \"The Art of Writing\".\n",
      "\n",
      "*The extract is about the difference between the arts.\n",
      "\n",
      "*The author says that writing is forgetting.\n",
      "\n",
      "*Literature is the most pleasant way to ignore life.\n",
      "\n",
      "*Music excites, the visual arts enliven, the living arts (such as dance and the art of acting) entertain.\n",
      "\n",
      "*The first, however, moves away from life by making it a sleep; the second, however, do not move away from life - some because they use visible and therefore vital formulas, others because they live from the same human life.\n",
      "\n",
      "*It is not the case of the literacy. This simulates life. A novel is a story of what never was and a drama is a novel given without narrative. A poem is the expression of ideas or feelings in language that no one uses, since no one speaks in verse.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q: \n",
      "What is the author's attitude towards the arts?\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*The author is Fernando Pessoa.\n",
      "\n",
      "*The extract is from his essay \"The Art of Writing\".\n",
      "\n",
      "*The extract is about the difference between the arts.\n",
      "\n",
      "*The author says that writing is forgetting.\n",
      "\n",
      "*Literature is the most pleasant way to\n"
     ]
    }
   ],
   "source": [
    "################# Sumarização de Texto #################\n",
    "################# \"World Knowledge\" e Compreensão #################\n",
    "\n",
    "context = r\"\"\"\n",
    "\"Writing is forgetting. Literature is the most pleasant way to ignore life. Music excites, the visual arts enliven, the living arts (such as dance and the art of acting) entertain. The first, however, moves away from life by making it a sleep; the second, however, do not move away from life - some because they use visible and therefore vital formulas, others because they live from the same human life.\n",
    "It is not the case of the literacy. This simulates life. A novel is a story of what never was and a drama is a novel given without narrative. A poem is the expression of ideas or feelings in language that no one uses, since no one speaks in verse.\"\n",
    "Fernando Pessoa\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Summarize the presented extract\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generate_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################  TRANSFORMAÇÃO DE FORMATOS  ####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tales from Shakespeare is an English children's book written by Charles Lamb and his sister Mary Lamb in 1807. The book is designed to make the stories of Shakespeare's plays familiar to the young. \n",
      "However, as noted in the author's Preface, \"[Shakespeare's] words are used whenever it seemed possible to bring them in; and in whatever has been added to give them the regular form of a connected story, diligent care has been taken to select such words as might least interrupt the effect of the beautiful English tongue in which he wrote: therefore, words introduced into our language since his time have been as far as possible avoided.\" \n",
      "\n",
      "\n",
      "Q: \n",
      "Traduza o parágrafo para o português brasileiro\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Machine Translation #################\n",
    "\n",
    "\n",
    "context = r\"\"\"\n",
    "Tales from Shakespeare is an English children's book written by Charles Lamb and his sister Mary Lamb in 1807. The book is designed to make the stories of Shakespeare's plays familiar to the young. \n",
    "However, as noted in the author's Preface, \"[Shakespeare's] words are used whenever it seemed possible to bring them in; and in whatever has been added to give them the regular form of a connected story, diligent care has been taken to select such words as might least interrupt the effect of the beautiful English tongue in which he wrote: therefore, words introduced into our language since his time have been as far as possible avoided.\" \n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Traduza o parágrafo para o português brasileiro\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### RETIRAR REFERÊNCIAS DO TEXTO #################################################################### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prompt = '''\n",
      "\n",
      "Perceba a diferenca entre cada contexto sujo e contexto limpo contido em <<Exemplos>>\n",
      "Aplique o mesmo raciocinio em <<Resposta>>\n",
      "Contexto limpo: em <<Resposta>> deve estar limpo de referencias do tipo [algo]\n",
      "\n",
      "<<Exemplos>>\n",
      "Contexto sujo: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
      "Contexto limpo: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
      "\n",
      "Contexto sujo: Ontem foi dia de ramos [32].\n",
      "Contexto limpo: Ontem foi dia de ramos.\n",
      "\n",
      "\n",
      "Q: \n",
      "\n",
      "<<Resposta>>\n",
      "Contexto sujo:\n",
      "Ao deixar o país, o imperador D.Pedro I selecionou três pessoas para cuidarem de seu filho e das filhas remanescentes.\n",
      "A primeira foi José Bonifácio de Andrada, seu amigo e líder influente da independência brasileira, nomeado tutor.[26][27]\n",
      "A segunda foi Mariana Carlota de Verna Magalhães Coutinho (depois Condessa de Belmonte), que detinha o cargo de aia desde o nascimento de Pedro II.[28]\n",
      "Quando bebê, D. Pedro II a chamava de \"dadama\", pois não pronunciava corretamente a palavra \"dama\".[15]\n",
      "Considerava-a sua mãe de criação, e continuaria a chamá-la, por afeto, de \"dadama\" mesmo já adulto.[3][29]\n",
      "A terceira pessoa escolhida foi Rafael, um veterano negro da Guerra da Cisplatina.[28][30]\n",
      "Rafael era um empregado do paço em quem D. Pedro I tinha profunda confiança e a quem pediu que olhasse por seu filho — pedido que Rafael levaria a termo pelo resto de sua vida.\n",
      "José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.[31][32][33]\n",
      "D. Pedro II passava os dias estudando,[34] com apenas duas horas livres para recreação.[35]\n",
      "Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama.[36]\n",
      "Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.[31][37]\n",
      "Sua paixão pela leitura lhe permitiu assimilar qualquer informação.[38]\n",
      "D. Pedro II não era um gênio,[39] mas inteligente[40] e com grande capacidade para acumular conhecimento facilmente.[41]\n",
      "O imperador teve uma infância solitária e infeliz.[8][42]\n",
      "A perda súbita de seus pais o assombraria por toda a vida;[43] ele teve poucos amigos de sua idade[28][36][44] e o contato com suas irmãs era limitado.[31][34][44]\n",
      "O ambiente em que foi criado o tornou tímido e carente,[45][46] enxergando nos livros refúgio e fuga do mundo real.\n",
      "\n",
      "Contexto limpo:\n",
      "\n",
      "A:\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*O imperador D. Pedro I selecionou três pessoas para cuidarem de seu filho e das filhas remanescentes.\n",
      "\n",
      "*A primeira foi José Bonifácio de Andrada, seu amigo e líder influente da independência brasileira, nomeado tutor.\n",
      "\n",
      "*A segunda foi Mariana Carlota de Verna Magalhães Coutinho (depois Condessa de Belmonte), que detinha o cargo de aia desde o nascimento de Pedro II.\n",
      "\n",
      "*A terceira pessoa escolhida foi Rafael, um veterano negro da Guerra da Cisplatina.\n",
      "\n",
      "*Rafael era um empregado do paço em quem D. Pedro I tinha profunda confiança e a quem pediu que olhasse por seu filho — pedido que Rafael levaria a termo pelo resto de sua vida.\n",
      "\n",
      "*José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.\n",
      "\n",
      "*D. Pedro II passava os dias estudando, com apenas duas horas livres para recreação.\n",
      "\n",
      "*Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.\n",
      "\n",
      "*Sua paixão pela leitura lhe permitiu assimilar qualquer informação.\n",
      "\n",
      "*D. Pedro II não era um gênio, mas inteligente e com grande capacidade para acumular conhecimento facilmente.\n",
      "\n",
      "*O imperador teve uma infância solitária e infeliz.\n",
      "\n",
      "*A perda súbita de seus pais o assombraria por toda a vida; ele teve poucos amigos de sua idade e o contato com suas irmãs era limitado.\n",
      "\n",
      "*O ambiente em que foi criado o tornou tímido e carente, enxergando nos livros refúgio e fuga do mundo real.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Retirar Referências do Texto #################\n",
    "\n",
    "context = r\"\"\"\n",
    "prompt = '''\n",
    "\n",
    "Perceba a diferenca entre cada contexto sujo e contexto limpo contido em <<Exemplos>>\n",
    "Aplique o mesmo raciocinio em <<Resposta>>\n",
    "Contexto limpo: em <<Resposta>> deve estar limpo de referencias do tipo [algo]\n",
    "\n",
    "<<Exemplos>>\n",
    "Contexto sujo: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
    "Contexto limpo: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
    "\n",
    "Contexto sujo: Ontem foi dia de ramos [32].\n",
    "Contexto limpo: Ontem foi dia de ramos.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "\n",
    "<<Resposta>>\n",
    "Contexto sujo:\n",
    "Ao deixar o país, o imperador D.Pedro I selecionou três pessoas para cuidarem de seu filho e das filhas remanescentes.\n",
    "A primeira foi José Bonifácio de Andrada, seu amigo e líder influente da independência brasileira, nomeado tutor.[26][27]\n",
    "A segunda foi Mariana Carlota de Verna Magalhães Coutinho (depois Condessa de Belmonte), que detinha o cargo de aia desde o nascimento de Pedro II.[28]\n",
    "Quando bebê, D. Pedro II a chamava de \"dadama\", pois não pronunciava corretamente a palavra \"dama\".[15]\n",
    "Considerava-a sua mãe de criação, e continuaria a chamá-la, por afeto, de \"dadama\" mesmo já adulto.[3][29]\n",
    "A terceira pessoa escolhida foi Rafael, um veterano negro da Guerra da Cisplatina.[28][30]\n",
    "Rafael era um empregado do paço em quem D. Pedro I tinha profunda confiança e a quem pediu que olhasse por seu filho — pedido que Rafael levaria a termo pelo resto de sua vida.\n",
    "José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.[31][32][33]\n",
    "D. Pedro II passava os dias estudando,[34] com apenas duas horas livres para recreação.[35]\n",
    "Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama.[36]\n",
    "Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.[31][37]\n",
    "Sua paixão pela leitura lhe permitiu assimilar qualquer informação.[38]\n",
    "D. Pedro II não era um gênio,[39] mas inteligente[40] e com grande capacidade para acumular conhecimento facilmente.[41]\n",
    "O imperador teve uma infância solitária e infeliz.[8][42]\n",
    "A perda súbita de seus pais o assombraria por toda a vida;[43] ele teve poucos amigos de sua idade[28][36][44] e o contato com suas irmãs era limitado.[31][34][44]\n",
    "O ambiente em que foi criado o tornou tímido e carente,[45][46] enxergando nos livros refúgio e fuga do mundo real.\n",
    "\n",
    "Contexto limpo:\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1500,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPOSTA COMPLETA\n",
    "\n",
    "Contexto limpo:\n",
    "\n",
    "A:\n",
    "\n",
    "*\n",
    "\n",
    "*O imperador D. Pedro I selecionou três pessoas para cuidarem de seu filho e das filhas remanescentes.\n",
    "\n",
    "*A primeira foi José Bonifácio de Andrada, seu amigo e líder influente da independência brasileira, nomeado tutor.\n",
    "\n",
    "*A segunda foi Mariana Carlota de Verna Magalhães Coutinho (depois Condessa de Belmonte), que detinha o cargo de aia desde o nascimento de Pedro II.\n",
    "\n",
    "*A terceira pessoa escolhida foi Rafael, um veterano negro da Guerra da Cisplatina.\n",
    "\n",
    "*Rafael era um empregado do paço em quem D. Pedro I tinha profunda confiança e a quem pediu que olhasse por seu filho — pedido que Rafael levaria a termo pelo resto de sua vida.\n",
    "\n",
    "*José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.\n",
    "\n",
    "*D. Pedro II passava os dias estudando, com apenas duas horas livres para recreação.\n",
    "\n",
    "*Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.\n",
    "\n",
    "*Sua paixão pela leitura lhe permitiu assimilar qualquer informação.\n",
    "\n",
    "*D. Pedro II não era um gênio, mas inteligente e com grande capacidade para acumular conhecimento facilmente.\n",
    "\n",
    "*O imperador teve uma infância solitária e infeliz.\n",
    "\n",
    "*A perda súbita de seus pais o assombraria por toda a vida; ele teve poucos amigos de sua idade e o contato com suas irmãs era limitado.\n",
    "\n",
    "*O ambiente em que foi criado o tornou tímido e carente, enxergando nos livros refúgio e fuga do mundo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Esta é uma tarefa de retirada de referências bibliográficas do texto. Estas referências estão escritas no formato \"['número']\".\n",
      "\n",
      "Exemplos:\n",
      "Contexto: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
      "Resposta: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
      "Contexto: Ontem foi dia de ramos [32].\n",
      "Resposta: Ontem foi dia de ramos.\n",
      "\n",
      "\n",
      "Q: \n",
      "Contexto: Ao deixar o país, o imperador D.Pedro I selecionou três pessoas para cuidarem de seu filho e das filhas remanescentes. A primeira foi José Bonifácio de Andrada, seu amigo e líder influente da independência brasileira, nomeado tutor.[26][27] A segunda foi Mariana Carlota de Verna Magalhães Coutinho (depois Condessa de Belmonte), que detinha o cargo de aia desde o nascimento de Pedro II.[28] Quando bebê, D. Pedro II a chamava de \"dadama\", pois não pronunciava corretamente a palavra \"dama\".[15] Considerava-a sua mãe de criação, e continuaria a chamá-la, por afeto, de \"dadama\" mesmo já adulto.[3][29] A terceira pessoa escolhida foi Rafael, um veterano negro da Guerra da Cisplatina.[28][30] Rafael era um empregado do paço em quem D. Pedro I tinha profunda confiança e a quem pediu que olhasse por seu filho — pedido que Rafael levaria a termo pelo resto de sua vida.\n",
      "José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.[31][32][33] D. Pedro II passava os dias estudando,[34] com apenas duas horas livres para recreação.[35] Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama.[36] Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.[31][37] Sua paixão pela leitura lhe permitiu assimilar qualquer informação.[38] D. Pedro II não era um gênio,[39] mas inteligente[40] e com grande capacidade para acumular conhecimento facilmente.[41]\n",
      "O imperador teve uma infância solitária e infeliz.[8][42] A perda súbita de seus pais o assombraria por toda a vida;[43] ele teve poucos amigos de sua idade[28][36][44] e o contato com suas irmãs era limitado.[31][34][44] O ambiente em que foi criado o tornou tímido e carente,[45][46] enxergando nos livros refúgio e fuga do mundo real.\n",
      "\n",
      "Retire as referências do texto dado e escreva a Resposta:\n",
      "\n",
      "\n",
      "A: Você pode usar o seguinte código:\n",
      "import re\n",
      "\n",
      "texto = \"\"\"\n",
      "Contexto: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
      "Resposta: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
      "Contexto: Ontem foi dia de ramos [32].\n",
      "Resposta: Ontem foi dia de ramos.\n",
      "Contexto: Ao deixar o país, o imperador D.Pedro I selecionou três pessoas para cuidarem de seu filho e das filhas remanescentes. A primeira foi José Bonifácio de Andrada, seu amigo e líder influente da independência brasileira, nomeado tutor.[26][27] A segunda foi Mariana Carlota de Verna Magalhães Coutinho (depois Condessa de Belmonte), que detinha o cargo de aia desde o nascimento de Pedro II.[28] Quando bebê, D. Pedro II a chamava de \"dadama\", pois não pronunciava corretamente a palavra \"dama\".[15] Considerava-a sua mãe de criação, e continuaria a chamá-la, por afeto, de \"dadama\" mesmo já adulto.[3][29] A terceira pessoa escolhida foi Rafael, um veterano negro da Guerra da Cisplatina.[28][30] Rafael era um empregado do paço em quem D. Pedro I tinha profunda confiança e a quem pediu que olhasse por seu filho — pedido que Rafael levaria a termo pelo resto de sua vida.\n",
      "José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.[31][32][33] D. Pedro II passava os dias estudando,[34] com apenas duas horas livres para recreação.[35] Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama.[36] Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.[31][37] Sua paixão pela leitura lhe permitiu assimilar qualquer informação.[38] D. Pedro II não era um gênio,[39] mas inteligente[40] e com grande capacidade para acumular conhecimento facilmente.[41]\n",
      "O imperador teve uma infância solitária e infeliz.[8][42] A perda súbita de seus pais o assombraria por toda a vida;[43] ele teve poucos amigos de sua idade[28][36][44] e o contato com suas irmãs era limitado.[31][34][44.\n",
      "O ambiente em que foi criado o tornou tímido e carente,[45][46] enxergando nos livros refúgio e fuga do mundo real.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Retirar Referências do Texto #################\n",
    "\n",
    "context = r\"\"\"\n",
    "\n",
    "Esta é uma tarefa de retirada de referências bibliográficas do texto. Estas referências estão escritas no formato \"['número']\".\n",
    "\n",
    "Exemplos:\n",
    "Contexto: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
    "Resposta: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
    "Contexto: Ontem foi dia de ramos [32].\n",
    "Resposta: Ontem foi dia de ramos.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"\"\"\n",
    "Contexto: Ao deixar o país, o imperador D.Pedro I selecionou três pessoas para cuidarem de seu filho e das filhas remanescentes. A primeira foi José Bonifácio de Andrada, seu amigo e líder influente da independência brasileira, nomeado tutor.[26][27] A segunda foi Mariana Carlota de Verna Magalhães Coutinho (depois Condessa de Belmonte), que detinha o cargo de aia desde o nascimento de Pedro II.[28] Quando bebê, D. Pedro II a chamava de \"dadama\", pois não pronunciava corretamente a palavra \"dama\".[15] Considerava-a sua mãe de criação, e continuaria a chamá-la, por afeto, de \"dadama\" mesmo já adulto.[3][29] A terceira pessoa escolhida foi Rafael, um veterano negro da Guerra da Cisplatina.[28][30] Rafael era um empregado do paço em quem D. Pedro I tinha profunda confiança e a quem pediu que olhasse por seu filho — pedido que Rafael levaria a termo pelo resto de sua vida.\n",
    "José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.[31][32][33] D. Pedro II passava os dias estudando,[34] com apenas duas horas livres para recreação.[35] Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama.[36] Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.[31][37] Sua paixão pela leitura lhe permitiu assimilar qualquer informação.[38] D. Pedro II não era um gênio,[39] mas inteligente[40] e com grande capacidade para acumular conhecimento facilmente.[41]\n",
    "O imperador teve uma infância solitária e infeliz.[8][42] A perda súbita de seus pais o assombraria por toda a vida;[43] ele teve poucos amigos de sua idade[28][36][44] e o contato com suas irmãs era limitado.[31][34][44] O ambiente em que foi criado o tornou tímido e carente,[45][46] enxergando nos livros refúgio e fuga do mundo real.\n",
    "\n",
    "Retire as referências do texto dado e escreva a Resposta:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1500,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Esta é uma tarefa de retirada de referências bibliográficas do texto. Estas referências estão escritas no formato \"[número]\".\n",
      "\n",
      "Exemplos:\n",
      "Contexto: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
      "Resposta: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
      "Contexto: Ontem foi dia de ramos [32].\n",
      "Resposta: Ontem foi dia de ramos.\n",
      "Contexto: Large Language Models (LLMs) have emerged as cutting-edge artificial intelligence systems designed to process and generate text, aiming\n",
      "to communicate coherently [1]. These developments have brought about a revolutionary transformation [2] by enabling the creation of Large Language Models (LLMs) that can approximate humanlevel performance on certain evaluation benchmarks [3], [4].\n",
      "Resposta: Large Language Models (LLMs) have emerged as cutting-edge artificial intelligence systems designed to process and generate text, aiming to communicate coherently. These developments have brought about a revolutionary transforbibliográficasmation by enabling the creation of Large Language Models (LLMs) that can approximate humanlevel performance on certain evaluation benchmarks.\n",
      "\n",
      "\n",
      "Q: \n",
      "Contexto: Ao deixar o país, o imperador D.Pedro I selecionou três pessoas para cuidarem de seu filho e das filhas remanescentes. A primeira foi José Bonifácio de Andrada, seu amigo e líder influente da independência brasileira, nomeado tutor.[26][27] A segunda foi Mariana Carlota de Verna Magalhães Coutinho (depois Condessa de Belmonte), que detinha o cargo de aia desde o nascimento de Pedro II.[28] Quando bebê, D. Pedro II a chamava de \"dadama\", pois não pronunciava corretamente a palavra \"dama\".[15] Considerava-a sua mãe de criação, e continuaria a chamá-la, por afeto, de \"dadama\" mesmo já adulto.[3][29] A terceira pessoa escolhida foi Rafael, um veterano negro da Guerra da Cisplatina.[28][30] Rafael era um empregado do paço em quem D. Pedro I tinha profunda confiança e a quem pediu que olhasse por seu filho — pedido que Rafael levaria a termo pelo resto de sua vida.\n",
      "José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.[31][32][33] D. Pedro II passava os dias estudando,[34] com apenas duas horas livres para recreação.[35] Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama.[36] Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.[31][37] Sua paixão pela leitura lhe permitiu assimilar qualquer informação.[38] D. Pedro II não era um gênio,[39] mas inteligente[40] e com grande capacidade para acumular conhecimento facilmente.[41]\n",
      "O imperador teve uma infância solitária e infeliz.[8][42] A perda súbita dos seus pais o assombraria por toda a vida;[43] ele teve poucos amigos de sua idade[28][36][44] e o contato com suas irmãs era limitado.[31][34][44] O ambiente em que foi criado o tornou tímido e carente,[45][46] enxergando nos livros refúgio e fuga do mundo real.\n",
      "\n",
      "Retire as referências do texto dado e escreva a Resposta:\n",
      "\n",
      "\n",
      "A: Você pode usar o seguinte código:\n",
      "import re\n",
      "\n",
      "texto = \"\"\"\n",
      "Contexto: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
      "Resposta: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
      "Contexto: Ontem foi dia de ramos [32].\n",
      "Resposta: Ontem foi dia de ramos.\n",
      "Contexto: Large Language Models (LLMs) have emerged as cutting-edge artificial intelligence systems designed to process and generate text, aiming\n",
      "to communicate coherently [1]. These developments have brought about a revolutionary transformation [2] by enabling the creation of Large Language Models (LLMs) that can approximate humanlevel performance on certain evaluation benchmarks [3], [4].\n",
      "Resposta: Large Language Models (LLMs) have emerged as cutting-edge artificial intelligence systems designed to process and generate text, aiming to communicate coherently. These developments have brought about a revolutionary transformation by enabling the creation of Large Language Models (LLMs) that can approximate humanlevel performance on certain evaluation benchmarks.\n",
      "\"\"\"\n",
      "\n",
      "pattern = re.compile(r'\\[(\\d+)\\]')\n",
      "\n",
      "for match in pattern.finditer(texto):\n",
      " print(match.group(1))\n",
      "\n",
      "Veja funcionando no Repl.it\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Retirar Referências do Texto #################\n",
    "\n",
    "context = r\"\"\"\n",
    "Esta é uma tarefa de retirada de referências bibliográficas do texto. Estas referências estão escritas no formato \"[número]\".\n",
    "\n",
    "Exemplos:\n",
    "Contexto: Joao da silva era carpinteiro [1][24]. Estudou na escola santa amelia [17] até os 18 anos de idade.\n",
    "Resposta: Joao da silva era carpinteiro. Estudou na escola santa amelia até os 18 anos de idade.\n",
    "Contexto: Ontem foi dia de ramos [32].\n",
    "Resposta: Ontem foi dia de ramos.\n",
    "Contexto: Large Language Models (LLMs) have emerged as cutting-edge artificial intelligence systems designed to process and generate text, aiming\n",
    "to communicate coherently [1]. These developments have brought about a revolutionary transformation [2] by enabling the creation of Large Language Models (LLMs) that can approximate humanlevel performance on certain evaluation benchmarks [3], [4].\n",
    "Resposta: Large Language Models (LLMs) have emerged as cutting-edge artificial intelligence systems designed to process and generate text, aiming to communicate coherently. These developments have brought about a revolutionary transforbibliográficasmation by enabling the creation of Large Language Models (LLMs) that can approximate humanlevel performance on certain evaluation benchmarks.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"\"\"\n",
    "Contexto: Ao deixar o país, o imperador D.Pedro I selecionou três pessoas para cuidarem de seu filho e das filhas remanescentes. A primeira foi José Bonifácio de Andrada, seu amigo e líder influente da independência brasileira, nomeado tutor.[26][27] A segunda foi Mariana Carlota de Verna Magalhães Coutinho (depois Condessa de Belmonte), que detinha o cargo de aia desde o nascimento de Pedro II.[28] Quando bebê, D. Pedro II a chamava de \"dadama\", pois não pronunciava corretamente a palavra \"dama\".[15] Considerava-a sua mãe de criação, e continuaria a chamá-la, por afeto, de \"dadama\" mesmo já adulto.[3][29] A terceira pessoa escolhida foi Rafael, um veterano negro da Guerra da Cisplatina.[28][30] Rafael era um empregado do paço em quem D. Pedro I tinha profunda confiança e a quem pediu que olhasse por seu filho — pedido que Rafael levaria a termo pelo resto de sua vida.\n",
    "José Bonifácio foi destituído de sua posição em dezembro de 1833 e substituído por outro tutor.[31][32][33] D. Pedro II passava os dias estudando,[34] com apenas duas horas livres para recreação.[35] Acordava às 06h30 da manhã e começava seus estudos às sete, continuando até as dez da noite, quando ia para cama.[36] Tomou-se grande cuidado em sua educação para formar valores e personalidade diferente da impulsividade e irresponsabilidade demonstradas por seu pai.[31][37] Sua paixão pela leitura lhe permitiu assimilar qualquer informação.[38] D. Pedro II não era um gênio,[39] mas inteligente[40] e com grande capacidade para acumular conhecimento facilmente.[41]\n",
    "O imperador teve uma infância solitária e infeliz.[8][42] A perda súbita dos seus pais o assombraria por toda a vida;[43] ele teve poucos amigos de sua idade[28][36][44] e o contato com suas irmãs era limitado.[31][34][44] O ambiente em que foi criado o tornou tímido e carente,[45][46] enxergando nos livros refúgio e fuga do mundo real.\n",
    "\n",
    "Retire as referências do texto dado e escreva a Resposta:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1500,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################  EXTRAÇÃO DE CONTEÚDO  ####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O evento da Apple aconteceu no Steve Jobs Theatre em Cupertino, Califórnia. \n",
      "Tim Cook, CEO da Apple, apresentou o novo iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana. \n",
      "O telefone vem em várias cores, apresenta um processador mais rápido e maior duração da bateria.\n",
      "\n",
      "\n",
      "Q: \n",
      "Analise o parágrafo, identifique Somente as entidades (\"entities\") dos tipos \"pessoa\", \"lugar\" e \"organização\" mencionadas no texto \n",
      "e, em seguida, produza os resultados em formato json.\n",
      "\n",
      "A: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Reconhecimento e Extração de Entidades #################\n",
    "\n",
    "\n",
    "context = r\"\"\"\n",
    "O evento da Apple aconteceu no Steve Jobs Theatre em Cupertino, Califórnia. \n",
    "Tim Cook, CEO da Apple, apresentou o novo iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana. \n",
    "O telefone vem em várias cores, apresenta um processador mais rápido e maior duração da bateria.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Analise o parágrafo, identifique Somente as entidades (\"entities\") dos tipos \"pessoa\", \"lugar\" e \"organização\" mencionadas no texto \n",
    "e, em seguida, produza os resultados em formato json.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O evento da Apple aconteceu no Steve Jobs Theatre em Cupertino, Califórnia. \n",
      "Tim Cook, CEO da Apple, apresentou o novo iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana. \n",
      "O telefone vem em várias cores, apresenta um processador mais rápido e maior duração da bateria.\n",
      "\n",
      "\n",
      "Q: \n",
      "Analise o parágrafo, identifique Somente as entities dos tipos \"pessoa\", \"lugar\" e \"organização\" mencionadas no texto e, em seguida, produza os resultados em formato json.\n",
      "\n",
      "A: O parágrafo que você está analisando é o seguinte:\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*A Apple anunciou o iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana.\n",
      "\n",
      "\n",
      "O resultado em formato json é:\n",
      "{\n",
      " \"entity\": \"pessoa\",\n",
      " \"type\": \"organização\",\n",
      " \"value\": \"Apple\"\n",
      "}\n",
      "\n",
      "\n",
      "A: O parágrafo que você está analisando é o seguinte:\n",
      "\n",
      "\n",
      "*\n",
      "\n",
      "*A Apple anunciou o iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana.\n",
      "\n",
      "\n",
      "O resultado em formato json é:\n",
      "{\n",
      " \"entity\": \"pessoa\",\n",
      " \"type\": \"organização\",\n",
      " \"value\": \"Apple\"\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Reconhecimento e Extração de Entidades #################\n",
    "\n",
    "\n",
    "context = r\"\"\"\n",
    "O evento da Apple aconteceu no Steve Jobs Theatre em Cupertino, Califórnia. \n",
    "Tim Cook, CEO da Apple, apresentou o novo iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana. \n",
    "O telefone vem em várias cores, apresenta um processador mais rápido e maior duração da bateria.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Analise o parágrafo, identifique Somente as entities dos tipos \"pessoa\", \"lugar\" e \"organização\" mencionadas no texto e, em seguida, produza os resultados em formato json.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPOSTA COMPLETA\n",
    "\n",
    "A: O parágrafo que você está analisando é o seguinte:\n",
    "\n",
    "*A Apple anunciou o iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana.\n",
    "\n",
    "\n",
    "O resultado em formato json é:\n",
    "{\n",
    " \"entity\": \"pessoa\",\n",
    " \"type\": \"organização\",\n",
    " \"value\": \"Apple\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O evento da Apple aconteceu no Steve Jobs Theatre em Cupertino, Califórnia. \n",
      "Tim Cook, CEO da Apple, apresentou o novo iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana. \n",
      "O telefone vem em várias cores, apresenta um processador mais rápido e maior duração da bateria.\n",
      "\n",
      "\n",
      "Q: \n",
      "Analise o parágrafo, identifique em formato JSON Somente as entidades (\"entities\") dos tipos \"pessoa\", \"lugar\" e \"organização\" mencionadas no texto.\n",
      "\n",
      "A:\n",
      "\n",
      "\n",
      "{\n",
      " \"pessoa\": [\n",
      " {\n",
      " \"nome\": \"Tim Cook\",\n",
      " \"sobrenome\": \"Cook\",\n",
      " \"email\": \"tim@apple.com\",\n",
      " \"telefone\": \"+1 408 999 9999\",\n",
      " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
      " \"organização\": \"Apple Inc.\",\n",
      " \"foto\": \"https://www.apple.com/images/tim-cook.jpg\"\n",
      " },\n",
      " {\n",
      " \"nome\": \"Jony Ive\",\n",
      " \"sobrenome\": \"Ive\",\n",
      " \"email\": \"jony@apple.com\",\n",
      " \"telefone\": \"+1 408 999 9999\",\n",
      " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
      " \"organização\": \"Apple Inc.\",\n",
      " \"foto\": \"https://www.apple.com/images/jony-ive.jpg\"\n",
      " },\n",
      " {\n",
      " \"nome\": \"Steve Jobs\",\n",
      " \"sobrenome\": \"Jobs\",\n",
      " \"email\": \"steve@apple.com\",\n",
      " \"telefone\": \"+1 408 999 9999\",\n",
      " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
      " \"organização\": \"Apple Inc.\",\n",
      " \"foto\": \"https://www.apple.com/images/steve-jobs.jpg\"\n",
      " },\n",
      " {\n",
      " \"nome\": \"Jeff Williams\",\n",
      " \"sobrenome\": \"Williams\",\n",
      " \"email\": \"jeff@apple.com\",\n",
      " \"telefone\": \"+1 408 999 9999\",\n",
      " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
      " \"organização\": \"Apple Inc.\",\n",
      " \"foto\": \"https://www.apple.com/images/jeff-williams.jpg\"\n",
      " },\n",
      " {\n",
      " \"nome\": \"Phil Schiller\",\n",
      " \"sobrenome\": \"Schiller\",\n",
      " \"email\": \"phil@apple.com\",\n",
      " \"telefone\": \"+1 408 999 9999\",\n",
      " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
      " \"organização\": \"Apple Inc.\",\n",
      " \"foto\": \"https://www.apple.com/images/phil-schiller.jpg\"\n",
      " },\n",
      " {\n",
      " \"nome\": \"Mike Rockwell\",\n",
      " \"sobrenome\": \"Rockwell\",\n",
      " \"email\": \"mike@apple.com\",\n",
      " \"telefone\": \"+1 408 999 9999\",\n",
      " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
      " \"organização\": \"Apple Inc.\",\n",
      " \"foto\": \"https://www.apple.com/images/mike-rockwell.jpg\"\n",
      " },\n",
      " {\n",
      " \"nome\": \"Kate Adams\",\n",
      " \"sobrenome\": \"Adams\",\n",
      " \"email\": \"kate@apple.com\",\n",
      " \"telefone\": \"+1 408 999 9999\",\n",
      " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
      " \"organização\": \"Apple Inc.\",\n",
      " \"foto\": \"https://www.apple.com/images/kate-adams.jpg\"\n",
      " },\n",
      " {\n",
      " \"nome\": \"Jonathan Ive\",\n",
      " \"sobrenome\": \"Ive\",\n",
      " \"email\": \"jonathan@apple.com\",\n",
      " \"telefone\": \"+1 408 999 9999\",\n",
      " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
      " \"organização\": \"Apple Inc.\",\n",
      " \"foto\": \"https://www.apple.com/images/jonathan-ive.jpg\"\n",
      " },\n",
      " {\n",
      " \"nome\": \"Jonathan Ive\",\n",
      " \"sobrenome\": \"\n"
     ]
    }
   ],
   "source": [
    "################# Reconhecimento e Extração de Entidades #################\n",
    "\n",
    "\n",
    "context = r\"\"\"\n",
    "O evento da Apple aconteceu no Steve Jobs Theatre em Cupertino, Califórnia. \n",
    "Tim Cook, CEO da Apple, apresentou o novo iPhone 15, que estará disponível para pré-encomenda a partir da próxima semana. \n",
    "O telefone vem em várias cores, apresenta um processador mais rápido e maior duração da bateria.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Analise o parágrafo, identifique em formato JSON Somente as entidades (\"entities\") dos tipos \"pessoa\", \"lugar\" e \"organização\" mencionadas no texto.\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A resposta completa foi:\n",
    "\n",
    "A:\n",
    "\n",
    "{\n",
    " \"pessoa\": [\n",
    " {\n",
    " \"nome\": \"Tim Cook\",\n",
    " \"sobrenome\": \"Cook\",\n",
    " \"email\": \"tim@apple.com\",\n",
    " \"telefone\": \"+1 408 999 9999\",\n",
    " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
    " \"organização\": \"Apple Inc.\",\n",
    " \"foto\": \"https://www.apple.com/images/tim-cook.jpg\"\n",
    " },\n",
    " {\n",
    " \"nome\": \"Jony Ive\",\n",
    " \"sobrenome\": \"Ive\",\n",
    " \"email\": \"jony@apple.com\",\n",
    " \"telefone\": \"+1 408 999 9999\",\n",
    " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
    " \"organização\": \"Apple Inc.\",\n",
    " \"foto\": \"https://www.apple.com/images/jony-ive.jpg\"\n",
    " },\n",
    " {\n",
    " \"nome\": \"Steve Jobs\",\n",
    " \"sobrenome\": \"Jobs\",\n",
    " \"email\": \"steve@apple.com\",\n",
    " \"telefone\": \"+1 408 999 9999\",\n",
    " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
    " \"organização\": \"Apple Inc.\",\n",
    " \"foto\": \"https://www.apple.com/images/steve-jobs.jpg\"\n",
    " },\n",
    " {\n",
    " \"nome\": \"Jeff Williams\",\n",
    " \"sobrenome\": \"Williams\",\n",
    " \"email\": \"jeff@apple.com\",\n",
    " \"telefone\": \"+1 408 999 9999\",\n",
    " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
    " \"organização\": \"Apple Inc.\",\n",
    " \"foto\": \"https://www.apple.com/images/jeff-williams.jpg\"\n",
    " },\n",
    " {\n",
    " \"nome\": \"Phil Schiller\",\n",
    " \"sobrenome\": \"Schiller\",\n",
    " \"email\": \"phil@apple.com\",\n",
    " \"telefone\": \"+1 408 999 9999\",\n",
    " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
    " \"organização\": \"Apple Inc.\",\n",
    " \"foto\": \"https://www.apple.com/images/phil-schiller.jpg\"\n",
    " },\n",
    " {\n",
    " \"nome\": \"Mike Rockwell\",\n",
    " \"sobrenome\": \"Rockwell\",\n",
    " \"email\": \"mike@apple.com\",\n",
    " \"telefone\": \"+1 408 999 9999\",\n",
    " \"endereço\": \"1 Infinite Loop, Cupertino, CA 95014\",\n",
    " \"organização\": \"Apple Inc.\",\n",
    " \"foto\": \"https://www.apple.com/images/mike-rockwell.jpg\"\n",
    " },\n",
    " {\n",
    " \"nome\": \"Kate Adams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elon Musk fundou a SpaceX em 2002 com o objetivo de reduzir os custos de transporte espacial e possibilitar a colonização de Marte.\n",
      "\n",
      "\n",
      "Q: \n",
      "Analise a frase e extraia o relacionamento entre duas entidades e, em seguida, produza os resultados indicando: entities e relatiohships entre estas no formato JSON\n",
      "\n",
      "A: Você pode usar o seguinte código:\n",
      "import json\n",
      "\n",
      "def get_relationships(text):\n",
      " entities = []\n",
      " relationships = []\n",
      "\n",
      " for line in text.splitlines():\n",
      " if line.startswith('{'):\n",
      " entities.append(line.split(':')[1])\n",
      " elif line.startswith('}') or line.startswith('}'):\n",
      " relationships.append(line.split(':')[1])\n",
      "\n",
      " return entities, relationships\n",
      "\n",
      "text = '''\n",
      "{\n",
      " \"entities\": [\n",
      " \"A\",\n",
      " \"B\",\n",
      " \"C\",\n",
      " \"D\",\n",
      " \"E\",\n",
      " \"F\",\n",
      " \"G\",\n",
      " \"H\",\n",
      " \"I\",\n",
      " \"J\",\n",
      " \"K\",\n",
      " \"L\",\n",
      " \"M\",\n",
      " \"N\",\n",
      " \"O\",\n",
      " \"P\",\n",
      " \"Q\",\n",
      " \"R\",\n",
      " \"S\",\n",
      " \"T\",\n",
      " \"U\",\n",
      " \"V\",\n",
      " \"W\",\n",
      " \"X\",\n",
      " \"Y\",\n",
      " \"Z\"\n",
      " ],\n",
      " \"relationships\": [\n",
      " \"A:B\",\n",
      " \"A:C\",\n",
      " \"A:D\",\n",
      " \"A:E\",\n",
      " \"A:F\",\n",
      " \"A:G\",\n",
      " \"A:H\",\n",
      " \"A:I\",\n",
      " \"A:J\",\n",
      " \"A:K\",\n",
      " \"A:L\",\n",
      " \"A:M\",\n",
      " \"A:N\",\n",
      " \"A:O\",\n",
      " \"A:P\",\n",
      " \"A:Q\",\n",
      " \"A:R\",\n",
      " \"A:S\",\n",
      " \"A:T\",\n",
      " \"A:U\",\n",
      " \"A:V\",\n",
      " \"A:W\",\n",
      " \"A:X\",\n",
      " \"A:Y\",\n",
      " \"A:Z\"\n",
      " ]\n",
      "}\n",
      "'''\n",
      "\n",
      "entities, relationships = get_relationships(text)\n",
      "\n",
      "print(entities)\n",
      "print(relationships)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################# Extração de Relações #################\n",
    "\n",
    "\n",
    "context = r\"\"\"\n",
    "Elon Musk fundou a SpaceX em 2002 com o objetivo de reduzir os custos de transporte espacial e possibilitar a colonização de Marte.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Analise a frase e extraia o relacionamento entre duas entidades e, em seguida, produza os resultados indicando: entities e relatiohships entre estas no formato JSON\n",
    "\"\"\"\n",
    "\n",
    "# Combinação do contexto e da questão para formar o prompt\n",
    "prompt = context + \"\\n\\nQ: \" + question + \"\\nA:\"\n",
    "\n",
    "# Tokenização do prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device) # Certificando de que os IDs estão no dispositivo correto (e no mesmo que o modelo)\n",
    "\n",
    "# Geração da resposta\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=1000,\n",
    "    #temperature=0.8,\n",
    "    top_k=50,\n",
    "    #top_p=0.95\n",
    ")\n",
    "\n",
    "# Decodificação e impressão da resposta\n",
    "answer = tokenizer.batch_decode(generation_output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
